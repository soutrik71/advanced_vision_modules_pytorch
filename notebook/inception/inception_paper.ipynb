{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception otherwise known as GoogLeNet Straight out of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run/code/Users/soutrik.chowdhury/advanced_vision_modules_pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run/code/Users/soutrik.chowdhury/advanced_vision_modules_pytorch\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from torchview import draw_graph\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torcheval.metrics import MulticlassAccuracy, BinaryAccuracy\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import (\n",
    "    OneCycleLR,\n",
    "    StepLR,\n",
    "    ExponentialLR,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import albumentations as alb\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(\n",
    "    train_loss,\n",
    "    val_loss,\n",
    "    train_acc,\n",
    "    val_acc,\n",
    "    labels,\n",
    "    colors,\n",
    "    loss_legend_loc=\"upper center\",\n",
    "    acc_legend_loc=\"upper left\",\n",
    "    legend_font=5,\n",
    "    fig_size=(16, 10),\n",
    "    sub_plot1=(1, 2, 1),\n",
    "    sub_plot2=(1, 2, 2),\n",
    "):\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.figure\n",
    "\n",
    "    plt.subplot(sub_plot1[0], sub_plot1[1], sub_plot1[2])\n",
    "\n",
    "    for i in range(len(train_loss)):\n",
    "        x_train = range(len(train_loss[i]))\n",
    "        x_val = range(len(val_loss[i]))\n",
    "\n",
    "        min_train_loss = np.array(train_loss[i]).min()\n",
    "\n",
    "        min_val_loss = np.array(val_loss[i]).min()\n",
    "\n",
    "        plt.plot(\n",
    "            x_train,\n",
    "            train_loss[i],\n",
    "            linestyle=\"-\",\n",
    "            color=\"tab:{}\".format(colors[i]),\n",
    "            label=\"TRAIN ({0:.4}): {1}\".format(min_train_loss, labels[i]),\n",
    "        )\n",
    "        plt.plot(\n",
    "            x_val,\n",
    "            val_loss[i],\n",
    "            linestyle=\"--\",\n",
    "            color=\"tab:{}\".format(colors[i]),\n",
    "            label=\"VALID ({0:.4}): {1}\".format(min_val_loss, labels[i]),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"epoch no.\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend(loc=loss_legend_loc, prop={\"size\": legend_font})\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "    plt.subplot(sub_plot2[0], sub_plot2[1], sub_plot2[2])\n",
    "\n",
    "    for i in range(len(train_acc)):\n",
    "        x_train = range(len(train_acc[i]))\n",
    "        x_val = range(len(val_acc[i]))\n",
    "\n",
    "        max_train_acc = np.array(train_acc[i]).max()\n",
    "\n",
    "        max_val_acc = np.array(val_acc[i]).max()\n",
    "\n",
    "        plt.plot(\n",
    "            x_train,\n",
    "            train_acc[i],\n",
    "            linestyle=\"-\",\n",
    "            color=\"tab:{}\".format(colors[i]),\n",
    "            label=\"TRAIN ({0:.4}): {1}\".format(max_train_acc, labels[i]),\n",
    "        )\n",
    "        plt.plot(\n",
    "            x_val,\n",
    "            val_acc[i],\n",
    "            linestyle=\"--\",\n",
    "            color=\"tab:{}\".format(colors[i]),\n",
    "            label=\"VALID ({0:.4}): {1}\".format(max_val_acc, labels[i]),\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"epoch no.\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(loc=acc_legend_loc, prop={\"size\": legend_font})\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "        delta=1e-5,\n",
    "        trace_func=print,\n",
    "        path=\"models\",\n",
    "        model_name=\"model.pt\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.model_name = model_name\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model, epoch):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(\n",
    "                f\"EarlyStopping counter: {self.counter} out of {self.patience}\"\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "            )\n",
    "        os.makedirs(self.path, exist_ok=True)\n",
    "        torch.save(model.state_dict(), os.path.join(self.path, self.model_name))\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get device (if GPU is available, use GPU)\"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "set_seed(42)\n",
    "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "device = get_device()\n",
    "print(device)\n",
    "batch_size = 512\n",
    "epochs = 25\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the image classes\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform for the dataset using Compose from albumentations\n",
    "def data_augmentations():\n",
    "    \"\"\"Data Augmentations for the CIFAR10 dataset using albumentations library\"\"\"\n",
    "    means = [0.4914, 0.4822, 0.4465]\n",
    "    stds = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "    train_transforms = alb.Compose(\n",
    "        [\n",
    "            alb.Normalize(mean=means, std=stds, always_apply=True),\n",
    "            alb.PadIfNeeded(min_height=40, min_width=40, always_apply=True),\n",
    "            alb.RandomCrop(height=32, width=32, always_apply=True),\n",
    "            alb.HorizontalFlip(),\n",
    "            alb.CoarseDropout(\n",
    "                max_holes=1,\n",
    "                max_height=8,\n",
    "                max_width=8,\n",
    "                min_holes=1,\n",
    "                min_height=8,\n",
    "                min_width=8,\n",
    "                fill_value=means,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = alb.Compose(\n",
    "        [\n",
    "            alb.Normalize(mean=means, std=stds, always_apply=True),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    return train_transforms, test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# downloading train and test data\n",
    "train = datasets.CIFAR10(\"./data\", train=True, download=True)\n",
    "test = datasets.CIFAR10(\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDS(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms, test_transforms = data_augmentations()\n",
    "train_dateset = CifarDS(train.data, train.targets, train_transforms)\n",
    "test_dateset = CifarDS(test.data, test.targets, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(\n",
    "    train_dateset, test_dateset, train_transforms, test_transforms, dataloader_args\n",
    "):\n",
    "    \"\"\"Data loader for the CIFAR10 dataset\"\"\"\n",
    "    # Loading custom datasets\n",
    "    train_dateset = CifarDS(train_dateset.data, train_dateset.targets, train_transforms)\n",
    "    test_dateset = CifarDS(test_dateset.data, test_dateset.targets, test_transforms)\n",
    "    # train dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(train_dateset, **dataloader_args)\n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(test_dateset, **dataloader_args)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "6\n",
      "tensor(-0.3312)\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_dateset:\n",
    "    print(data.shape)\n",
    "    print(label)\n",
    "    print(data.mean())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = (\n",
    "    dict(shuffle=True, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    if device.type == \"cuda\"\n",
    "    else dict(shuffle=True, batch_size=batch_size)\n",
    ")\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_dateset, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test_dateset, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch_env/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/anaconda/envs/torch_env/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Lenet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://miro.medium.com/v2/resize:fit:828/format:webp/1*yGcmBL1Nyqpj2lNG2sj5Wg.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv Block for the dataprep part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional Block for Initial data prep for Inception block\"\"\"\n",
    "\n",
    "    def __int__(self, in_channels, out_channels, **kwargs):\n",
    "        super(ConvBlock, self).__int__()\n",
    "        self.convb = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convb(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we design the inception block which is the most important part we throw the model three options: one-by-one, three-by-three, and five-by-five kernels, and we let the model figure out how to weigh and process information from these kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    \"\"\"Inception Block for the model\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_11, in_33, out_33, in_55, out_55, out_pool):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        # 1*1 block\n",
    "        self.branch11 = nn.Conv2d(in_channels, out_11, kernel_size=1)\n",
    "        # 1*1 -> 3*3 block\n",
    "        self.branch33 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_33, kernel_size=1, padding=0),\n",
    "            nn.Conv2d(in_33, out_33, kernel_size=3, padding=1),\n",
    "        )\n",
    "        # 1*1 -> 5*5 block\n",
    "        self.branch55 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_55, kernel_size=1, padding=0),\n",
    "            nn.Conv2d(in_55, out_55, kernel_size=5, padding=2),\n",
    "        )\n",
    "        # maxpool -> 1*1 block\n",
    "        self.branchpool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, out_pool, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(\n",
    "            [self.branch11(x), self.branch33(x), self.branch55(x), self.branchpool(x)],\n",
    "            1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "InceptionBlock                           [1, 256, 32, 32]          --\n",
       "├─Conv2d: 1-1                            [1, 64, 32, 32]           12,352\n",
       "├─Sequential: 1-2                        [1, 128, 32, 32]          --\n",
       "│    └─Conv2d: 2-1                       [1, 96, 32, 32]           18,528\n",
       "│    └─Conv2d: 2-2                       [1, 128, 32, 32]          110,720\n",
       "├─Sequential: 1-3                        [1, 32, 32, 32]           --\n",
       "│    └─Conv2d: 2-3                       [1, 16, 32, 32]           3,088\n",
       "│    └─Conv2d: 2-4                       [1, 32, 32, 32]           12,832\n",
       "├─Sequential: 1-4                        [1, 32, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 192, 32, 32]          --\n",
       "│    └─Conv2d: 2-6                       [1, 32, 32, 32]           6,176\n",
       "==========================================================================================\n",
       "Total params: 163,696\n",
       "Trainable params: 163,696\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 167.62\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 3.01\n",
       "Params size (MB): 0.65\n",
       "Estimated Total Size (MB): 4.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_block = InceptionBlock(192, 64, 96, 128, 16, 32, 32).to(device)\n",
    "summary(inception_block, input_size=(1,192, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define the auxillary classifiers which will be optional in the main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
