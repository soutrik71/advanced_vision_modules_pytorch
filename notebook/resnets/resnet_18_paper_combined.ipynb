{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run/code/Users/soutrik.chowdhury/advanced_vision_modules_pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run/code/Users/soutrik.chowdhury/advanced_vision_modules_pytorch\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks deals in a different way of solving the RESENT problem in one block rather than 2 that we have discussed in the previous notebook:\n",
    "* We will attempt solving resnet 18 from the point of view of CIFAR-10 but same applies for Resnet-34\n",
    "* https://debuggercafe.com/wp-content/uploads/2022/08/resnet-models-from-table.png\n",
    "* https://debuggercafe.com/implementing-resnet18-in-pytorch-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torch import Tensor\n",
    "from typing import Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic blocks \n",
    "\n",
    "https://debuggercafe.com/wp-content/uploads/2022/08/resnet18-basic-blocks-1.png\n",
    "\n",
    "https://debuggercafe.com/wp-content/uploads/2022/08/resnet-residual-block-for-resnet18-from-scratch-using-pytorch.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.float32\n",
      "cuda:0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random_tensor_batch = torch.rand((16, 3, 32, 32), device=device, dtype=torch.float32)\n",
    "print(random_tensor_batch.shape)\n",
    "print(random_tensor_batch.dtype)\n",
    "print(random_tensor_batch.device)\n",
    "print(random_tensor_batch.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicResentBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expansion, downsample=None):\n",
    "        super(BasicResentBlock, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels * self.expansion,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion),\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass which follows the flow as :\n",
    "        First convolution block -> Second convolution block -> Downsample -> Add identity -> ReLU\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.convblock1(x)\n",
    "        out = self.convblock2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # print(out.shape)\n",
    "        # print(identity.shape)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BasicResentBlock                         [1, 3, 32, 32]            --\n",
       "├─Sequential: 1-1                        [1, 3, 32, 32]            --\n",
       "│    └─Conv2d: 2-1                       [1, 3, 32, 32]            81\n",
       "│    └─BatchNorm2d: 2-2                  [1, 3, 32, 32]            6\n",
       "│    └─ReLU: 2-3                         [1, 3, 32, 32]            --\n",
       "├─Sequential: 1-2                        [1, 3, 32, 32]            --\n",
       "│    └─Conv2d: 2-4                       [1, 3, 32, 32]            81\n",
       "│    └─BatchNorm2d: 2-5                  [1, 3, 32, 32]            6\n",
       "├─ReLU: 1-3                              [1, 3, 32, 32]            --\n",
       "==========================================================================================\n",
       "Total params: 174\n",
       "Trainable params: 174\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.17\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.10\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.11\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_block = BasicResentBlock(in_channels=3, out_channels=3, stride=1, expansion=1).to(device)\n",
    "summary(resnet_block, input_size=(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "block_op = resnet_block(random_tensor_batch)\n",
    "print(block_op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, resnet_ver, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        if resnet_ver == \"resnet18\":\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "        elif resnet_ver == \"resnet34\":\n",
    "            layers = [3, 4, 6, 3]\n",
    "            self.expansion = 1\n",
    "\n",
    "        # First lets declare the presenet block conv->bn->relu->maxpool with paper wise config\n",
    "        self.presentation = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=64,\n",
    "                kernel_size=(7, 7),\n",
    "                stride=(2, 2),\n",
    "                padding=(3, 3),\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)),\n",
    "        )\n",
    "\n",
    "        # Now lets declare the resnet blocks\n",
    "        self.resnet_l1 = self._make_resent_layer(64, 64, 1, layers[0])\n",
    "        self.resnet_l2 = self._make_resent_layer(64, 128, 2, layers[1])\n",
    "        self.resnet_l3 = self._make_resent_layer(128, 256, 2, layers[2])\n",
    "        self.resnet_l4 = self._make_resent_layer(256, 512, 2, layers[3])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * self.expansion, num_classes),\n",
    "        )\n",
    "\n",
    "    def _make_resent_layer(self, in_channels, out_channels, stride, blocks):\n",
    "        if stride == 1:\n",
    "            downsample = None\n",
    "        else:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels * self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # adding the layer with dotted connection ie the downsampling block\n",
    "        layers.append(\n",
    "            BasicResentBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                stride=stride,\n",
    "                expansion=self.expansion,\n",
    "                downsample=downsample,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # adding the remaining blocks\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                BasicResentBlock(\n",
    "                    out_channels, out_channels, 1, expansion=self.expansion\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.presentation(x)\n",
    "        x = self.resnet_l1(x)\n",
    "        x = self.resnet_l2(x)\n",
    "        x = self.resnet_l3(x)\n",
    "        x = self.resnet_l4(x)\n",
    "        print(\"Dimensions of the last convolutional feature map: \", x.shape)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the last convolutional feature map:  torch.Size([1, 512, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 64, 8, 8]             --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 16, 16]           9,408\n",
       "│    └─BatchNorm2d: 2-2                  [1, 64, 16, 16]           128\n",
       "│    └─ReLU: 2-3                         [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d: 2-4                    [1, 64, 8, 8]             --\n",
       "├─Sequential: 1-2                        [1, 64, 8, 8]             --\n",
       "│    └─BasicResentBlock: 2-5             [1, 64, 8, 8]             --\n",
       "│    │    └─Sequential: 3-1              [1, 64, 8, 8]             36,992\n",
       "│    │    └─Sequential: 3-2              [1, 64, 8, 8]             36,992\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 8, 8]             --\n",
       "│    └─BasicResentBlock: 2-6             [1, 64, 8, 8]             --\n",
       "│    │    └─Sequential: 3-4              [1, 64, 8, 8]             36,992\n",
       "│    │    └─Sequential: 3-5              [1, 64, 8, 8]             36,992\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 8, 8]             --\n",
       "├─Sequential: 1-3                        [1, 128, 4, 4]            --\n",
       "│    └─BasicResentBlock: 2-7             [1, 128, 4, 4]            --\n",
       "│    │    └─Sequential: 3-7              [1, 128, 4, 4]            73,984\n",
       "│    │    └─Sequential: 3-8              [1, 128, 4, 4]            147,712\n",
       "│    │    └─Sequential: 3-9              [1, 128, 4, 4]            8,448\n",
       "│    │    └─ReLU: 3-10                   [1, 128, 4, 4]            --\n",
       "│    └─BasicResentBlock: 2-8             [1, 128, 4, 4]            --\n",
       "│    │    └─Sequential: 3-11             [1, 128, 4, 4]            147,712\n",
       "│    │    └─Sequential: 3-12             [1, 128, 4, 4]            147,712\n",
       "│    │    └─ReLU: 3-13                   [1, 128, 4, 4]            --\n",
       "├─Sequential: 1-4                        [1, 256, 2, 2]            --\n",
       "│    └─BasicResentBlock: 2-9             [1, 256, 2, 2]            --\n",
       "│    │    └─Sequential: 3-14             [1, 256, 2, 2]            295,424\n",
       "│    │    └─Sequential: 3-15             [1, 256, 2, 2]            590,336\n",
       "│    │    └─Sequential: 3-16             [1, 256, 2, 2]            33,280\n",
       "│    │    └─ReLU: 3-17                   [1, 256, 2, 2]            --\n",
       "│    └─BasicResentBlock: 2-10            [1, 256, 2, 2]            --\n",
       "│    │    └─Sequential: 3-18             [1, 256, 2, 2]            590,336\n",
       "│    │    └─Sequential: 3-19             [1, 256, 2, 2]            590,336\n",
       "│    │    └─ReLU: 3-20                   [1, 256, 2, 2]            --\n",
       "├─Sequential: 1-5                        [1, 512, 1, 1]            --\n",
       "│    └─BasicResentBlock: 2-11            [1, 512, 1, 1]            --\n",
       "│    │    └─Sequential: 3-21             [1, 512, 1, 1]            1,180,672\n",
       "│    │    └─Sequential: 3-22             [1, 512, 1, 1]            2,360,320\n",
       "│    │    └─Sequential: 3-23             [1, 512, 1, 1]            132,096\n",
       "│    │    └─ReLU: 3-24                   [1, 512, 1, 1]            --\n",
       "│    └─BasicResentBlock: 2-12            [1, 512, 1, 1]            --\n",
       "│    │    └─Sequential: 3-25             [1, 512, 1, 1]            2,360,320\n",
       "│    │    └─Sequential: 3-26             [1, 512, 1, 1]            2,360,320\n",
       "│    │    └─ReLU: 3-27                   [1, 512, 1, 1]            --\n",
       "├─Sequential: 1-6                        [1, 10]                   --\n",
       "│    └─AdaptiveAvgPool2d: 2-13           [1, 512, 1, 1]            --\n",
       "│    └─Flatten: 2-14                     [1, 512]                  --\n",
       "│    └─Linear: 2-15                      [1, 10]                   5,130\n",
       "==========================================================================================\n",
       "Total params: 11,181,642\n",
       "Trainable params: 11,181,642\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 37.03\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.81\n",
       "Params size (MB): 44.73\n",
       "Estimated Total Size (MB): 45.55\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(in_channels=3, resnet_ver=\"resnet18\", num_classes=10).to(device)\n",
    "summary(model, input_size=(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,181,642 total parameters.\n",
      "11,181,642 training parameters.\n",
      "Dimensions of the last convolutional feature map:  torch.Size([16, 512, 1, 1])\n",
      "torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "output = model(random_tensor_batch)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According the original Article:: https://debuggercafe.com/implementing-resnet18-in-pytorch-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None,\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Multiplicative factor for the subsequent conv2d layer's output channels.\n",
    "        # It is 1 for ResNet18 and ResNet34.\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels * self.expansion,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetMain(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        img_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Type[BasicBlock],\n",
    "        num_classes: int  = 1000\n",
    "    ) -> None:\n",
    "        super(ResNetMain, self).__init__()\n",
    "        if num_layers == 18:\n",
    "            # The following `layers` list defines the number of `BasicBlock` \n",
    "            # to use to build the network and how many basic blocks to stack\n",
    "            # together.\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n",
    "        # three layers. Here, kernel size is 7.\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7, \n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self, \n",
    "        block: Type[BasicBlock],\n",
    "        out_channels: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            \"\"\"\n",
    "            This should pass from `layer2` to `layer4` or \n",
    "            when building ResNets50 and above. Section 3.3 of the paper\n",
    "            Deep Residual Learning for Image Recognition\n",
    "            (https://arxiv.org/pdf/1512.03385v1.pdf).\n",
    "            \"\"\"\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels, \n",
    "                    out_channels*self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False \n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion\n",
    "            ))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # The spatial dimension of the final layer's feature \n",
    "        # map should be (7, 7) for all ResNets.\n",
    "        print('Dimensions of the last convolutional feature map: ', x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,181,642 total parameters.\n",
      "11,181,642 training parameters.\n",
      "Dimensions of the last convolutional feature map:  torch.Size([16, 512, 1, 1])\n",
      "torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "model = ResNetMain(img_channels=3, num_layers=18, block=BasicBlock, num_classes=10).to(device)\n",
    "summary(model)\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "output = model(random_tensor_batch)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This verifies that the ResNet architecture is correct. The next step is to train the model on the CIFAR-10 dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
